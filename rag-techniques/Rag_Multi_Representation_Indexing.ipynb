{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3839137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # reads .env and injects into environment\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "\n",
    "# retrieve from environment\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a739db93",
   "metadata": {},
   "source": [
    "Docs:\n",
    "\n",
    "https://blog.langchain.dev/semi-structured-multi-modal-rag/\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector\n",
    "\n",
    "Paper:\n",
    "\n",
    "https://arxiv.org/abs/2312.06648"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f05868c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2024-02-05-human-data-quality/\")\n",
    "docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1f04b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")\n",
    "    | ChatOpenAI(model=\"gpt-3.5-turbo\",max_retries=0)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "summaries = chain.batch(docs, {\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a39286db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from pydantic import Field\n",
    "\n",
    "# Custom Multi-Vector Retriever implementation\n",
    "class MultiVectorRetriever(BaseRetriever):\n",
    "    \"\"\"Retriever that searches summaries but returns full documents.\"\"\"\n",
    "    \n",
    "    vectorstore: Chroma = Field(...)\n",
    "    docstore: dict = Field(...)\n",
    "    id_key: str = Field(default=\"doc_id\")\n",
    "    search_kwargs: dict = Field(default_factory=lambda: {\"k\": 4})\n",
    "    \n",
    "    def _get_relevant_documents(\n",
    "        self, \n",
    "        query: str, \n",
    "        *, \n",
    "        run_manager: CallbackManagerForRetrieverRun = None\n",
    "    ):\n",
    "        # Search for relevant summaries\n",
    "        summary_docs = self.vectorstore.similarity_search(query, **self.search_kwargs)\n",
    "        \n",
    "        # Get doc_ids from summaries\n",
    "        doc_ids = [doc.metadata.get(self.id_key) for doc in summary_docs if self.id_key in doc.metadata]\n",
    "        \n",
    "        # Return full documents from docstore\n",
    "        full_docs = [self.docstore[doc_id] for doc_id in doc_ids if doc_id in self.docstore]\n",
    "        return full_docs\n",
    "\n",
    "# The vectorstore to use to index the summaries\n",
    "vectorstore = Chroma(collection_name=\"summaries\",\n",
    "                     embedding_function=OpenAIEmbeddings())\n",
    "\n",
    "# Simple in-memory storage for parent documents\n",
    "docstore = {}\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# Generate unique IDs for documents\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "\n",
    "# Store full documents\n",
    "for doc_id, doc in zip(doc_ids, docs):\n",
    "    docstore[doc_id] = doc\n",
    "\n",
    "# Create summary documents with doc_ids in metadata\n",
    "summary_docs = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]\n",
    "\n",
    "# Add summaries to vectorstore\n",
    "vectorstore.add_documents(summary_docs)\n",
    "\n",
    "# Create the retriever\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=docstore,\n",
    "    id_key=id_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecb3881b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'doc_id': 'bea633f4-2eb7-45c1-8939-f7086f0d3b17'}, page_content='This document discusses the concept of building autonomous agents powered by Large Language Models (LLM). It covers key components of LLM-powered agents, such as planning, memory, and tool use. Proof-of-concept examples like AutoGPT and GPT-Engineer are provided to demonstrate the potential applications of LLM-powered agents. Challenges, such as finite context length, reliability of natural language interface, and long-term planning, are also discussed. The document provides a comprehensive overview of the capabilities and limitations of LLM-powered autonomous agents.')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Memory in agents\"\n",
    "sub_docs = vectorstore.similarity_search(query,k=1)\n",
    "sub_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fec28b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LLM Powered Autonomous Agents | Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "|\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Posts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Archive\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tags\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FAQ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "\n",
      "\n",
      "Agent System Overview\n",
      "\n",
      "Component One: Planning\n",
      "\n",
      "Task Decomposition\n",
      "\n",
      "Self-Reflection\n",
      "\n",
      "\n",
      "Component Two: Memory\n",
      "\n",
      "Types of Memory\n",
      "\n",
      "Maximum Inner Product Search (MIPS)\n",
      "\n",
      "\n",
      "Component Three:\n"
     ]
    }
   ],
   "source": [
    "# Use invoke (Runnable API) - BaseRetriever implements Runnable\n",
    "# Temporarily set k=1 for this query\n",
    "original_k = retriever.search_kwargs.get(\"k\", 4)\n",
    "retriever.search_kwargs[\"k\"] = 1\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "retriever.search_kwargs[\"k\"] = original_k  # Reset to default\n",
    "\n",
    "if retrieved_docs:\n",
    "    print(retrieved_docs[0].page_content[0:500])\n",
    "else:\n",
    "    print(\"No documents retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b999e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a32a39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
